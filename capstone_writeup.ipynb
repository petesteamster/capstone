{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate two implemenatations of an imputation package called MICE. One implemenatation is written for R. It has been around since 2000. The other implementation is written for Python. It is much more recent than the R version.\n",
    "- The data is from Kaggle. It is the Ames Housing Dataset used for building models that predict sale price.\n",
    "- To compare the implementations, we used R-square scores. We also calculated an absolute sum of the different between imputed values and the baseline values. In this case, we treated the imputations in the same way predicted values is any regression are compared to actual values. \n",
    "- We found that, given a caveat, R MICE and Python MICE perform at the same level. The caveat is that Python MICE fails if the data is correlated (singular) to such a degree that a model with a single solution cannot be found. This is because Python MICE has a single impute model that is a type of linear regression. R Mice has several alternative imputation models. It Random Forest option can handle data with singlarity issues.\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation and Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the most part, our model was secondary to our goal. We needed a descent model, but the results of the model were not our goal. The model was used as a means to evaluate the imputation process of Python MICE and R MICE. We used a model we created from an earlier project. We tweaked it a bit. We used a log transformation on the target in order to make its distribution more normal. The model has an R-square score in the range of .8. \n",
    "- We used the Ame Housing Data. We assumed there was no missing data. An inspection of the data will show several categories with an 'NA' designation. We asuumed 'NA'to be valid. That is, we assumed 'NA' meant 'Not Applicable'. For example, the category 'Alley' indicates the type of alley that borders a given house. Most houses have no contiguous alleys. This the category is 'NA\". \n",
    "- Assuming there is no missing data allows us to treat it as a baseline. We take this baseline data and randomly\n",
    "remove points which provides us a set that contains simulated missing data. \n",
    "- As with most models, our model was based on features created from raw data. We created a large number of polynomial features. In an effort to trim the feature count down, we removed features that had an absolute correlation with the target (SalePrice) less than .25. We found that .25 gave us the best model. This resulted in approximately 160+ features.\n",
    "- Each time we train our model, we shuffled the data. Since the mix of the training data changes from run to run, the correlation between each feature and the target changes from run to run. Thus, for each run, different features fall above or below the .25 correlation threshold. Therefore, the feature count varies from run to run. \n",
    "- Because features drop in and out from run to run, we decided to use the final training data; that is the data \n",
    "built from the features after they were weed out by the coorelation threshold process.\n",
    "-  We performed the missing data simulation on the features with the top 5 correlations with the target. \n",
    "- We simulated 5%,10%, 15% and 50% missing data for each of these 5 features. This resulted in 4 files that were imputed with R and Python resulting in 8 training files which led to 8 models. Each of these models were valided using the exact same set of data for testing. The test data was not imputed. The models were built using imputed data.\n",
    "- Baseline r2 : .83\n",
    "- R Mice 5%   : .82\n",
    "- R Mice 10%  : .82\n",
    "- R Mice 15%  : .82\n",
    "- R Mice 50%  : .83\n",
    "- Py Mice 5%  : .82\n",
    "- Py Mice 10% : .83\n",
    "- Py Mice 15% : .83\n",
    "- Py Mice 50% : .82\n",
    "We can see that R Mice and Python Mice perform at the same level. Based on the fact that the r2 is consistant regardless of the degree of missing data, can we conclude Mice imputation \"rocks\"?\n",
    "We decided to see what happens if we impute using the mean values of a column and run the resulting data\n",
    "into a model. The r-square for mean imputation was .82. \n",
    "### In search of a better metric\n",
    "We decided to calculate a metric based on the difference between baseline and imputed data. We did this for 50% missing data. The metric is the sum of the absolute differences between R Mice and baseline, Py Mice and baseline and mean impute and baseline. \n",
    "- Mice R      : 876\n",
    "- Mice Py     : 813\n",
    "- Mean Impute : 1911\n",
    "- We conclude that R and Python impute at that same level. Also, they perform much better than mean imputation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
